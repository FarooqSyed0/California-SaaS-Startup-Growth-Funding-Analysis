"Week.Step","Task","Labs Mode Documentation Questions","Your Answers (Include Screenshots)","Status"
"1.1","Install and configure PostgreSQL on your Mac","What installation challenges did you encounter? Which configuration settings optimized performance for your project?","Successfully installed PostgreSQL using official installer. Configured default port 5432, set up authentication. Tuned shared buffers and workmem. Screenshot uploaded: postgresqlinstallation.png","âœ…ðŸ“· Done"
"1.2","Design table structure for funding data","How did you determine optimal data types and constraints? What normalization decisions did you make and why?","Used VARCHAR for names, TEXT for URLs, INTEGER for counts, DECIMAL for growth. Minimal normalization for simplicity, enforced NOT NULL on key fields. Screenshot uploaded: tableschemadesign.png","âœ…ðŸ“· Done"
"1.3","Research and download a free startup funding dataset","What criteria guided your dataset selection? How did you validate data quality and relevance for your analysis goals?","Chose Growjo for SaaS focus and growth metrics. Filtered for CA companies and 1-500 employees. Checked completeness of key variables. Screenshot uploaded: datasetsourceselection.png","âœ…ðŸ“· Done"
"1.4","Load data into Excel for initial exploration","What data formatting issues did you discover? How did you handle missing values and inconsistent data types?","Found inconsistencies in names and locations. 67 missing funding, 20 missing founded dates. Used Excel validation and conditional formatting. Screenshot uploaded: exceldataexploration.png","âœ…ðŸ“· Done"
"1.5","Identify key variables and check data quality","What percentage of data was complete for each key variable? Which quality issues required strategic analytical pivots?","Company names 100%, employees 99.5%, growth 98.8%, funding 32.9%. Pivoted to employee growth analysis due to missing funding data. Screenshot uploaded: dataqualityassessment.png","âœ…ðŸ“· Done"
"1.6","Define 3-4 core business impact questions","How did your data quality assessment inform your business questions? What stakeholder value do these questions address?","Focused on employee growth questions supported by high-quality data. Questions address SaaS scaling, company age, geography, and growth stages. Screenshot uploaded: businessquestionsdefinition.png","âœ…ðŸ“· Done"
"2.7","Import cleaned dataset into PostgreSQL","What import challenges did you resolve? How did you optimize table structure for analytical performance?","Fixed VARCHAR length errors in DBeaver by switching to TEXT for URL columns. Ensured all columns matched the cleaned CSV. Optimized data types. Removed obsolete table newtable after confirming all work references startupfundinganalysis. Ran DROP TABLE IF EXISTS newtable for cleanup. Screenshot uploaded: importsuccess.png","âœ…ðŸ“· Done"
"2.8","Test basic SQL queries","What specific validation queries did you run? What were the exact results (row counts, data ranges)? Which outliers did you discover and how did you handle them?","Ran row count, null checks, min/max, uniqueness, funding statistics, and duplicate checks. Results: Row count matched CSV, minimal nulls in key columns, realistic funding and employee ranges, no problematic duplicates. Screenshot uploaded: sqlvalidation.png","âœ…ðŸ“· Done"
"2.9","Write SQL queries to answer business questions","What were your exact SQL queries for each business impact question? What performance optimizations did you implement? What unexpected patterns did you discover in the data?","Drafted queries for employee growth, funding by location, and company age distribution. Discovered a few high-funding outliers and adjusted analysis to use median and percentiles. Screenshot uploaded: businessqueries.png","âœ…ðŸ“· Done"
"2.10","Use Python Pandas for further cleaning","Which data quality issues did Python reveal that SQL missed? What transformation logic did you apply? What statistical insights emerged?","Updated all .fillna operations to assign directly to DataFrame columns (e.g., df['employeegrowth'] = df['employeegrowth'].fillna(mediangrowth)) instead of using inplace=True. Completed data cleaning steps: standardized text fields, handled missing values, converted date columns, removed duplicates, and calculated company age. Screenshot uploaded: pythoncleaninganalysis.png","âœ…ðŸ“· Done"
"2.11","Create simple visualizations to validate insights","Which visualization types best represented your findings? What design decisions did you make and why? How did visuals change your analytical conclusions?","Uploaded startupfundingvisualizations.twbx to the src folder. Included screenshots: employeegrowthdistribution.png (histogram of employee growth), growthvsfunding.png (scatter plot of employee growth vs. total funding). Key findings: histogram revealed most companies have moderate employee growth, a few extreme outliers; scatter plot showed most companies cluster at lower funding/growth, with outliers. Visuals validated main patterns. Screenshots uploaded: employeegrowthdistribution.png, growthvsfunding.png","âœ…ðŸ“· Done"
"2.12","Set up Python Anaconda Jupyter Notebook","What configuration challenges did you encounter? Which libraries did you install beyond defaults? How did you optimize for your specific analysis needs?","Anaconda and Jupyter Notebook were already installed and configured prior to this step. Successfully ran Python code for data cleaning and analysis in Jupyter Notebook. No configuration challenges encountered. Common libraries used: pandas, numpy, matplotlib, seaborn. Environment optimized for data analysis workflows. Screenshot uploaded: jupytersetup.png","âœ…ðŸ“· Done"
"2.13","Ensure VS Code with Cursor AI is ready for development","Which extensions proved most valuable for data analysis? How did you configure the environment for optimal productivity? What integration challenges did you solve?","VS Code and Cursor AI are fully installed and configured. All core data analysis extensions are installed, including Python, Jupyter, Pylance, GitLens, Data Wrangler, and more, as shown in the attached extension list screenshot. No integration issues encountered; environment is ready for data analysis workflows. Screenshot uploaded: vscode-extensions-list.jpg","âœ…ðŸ“· Done"
"2.14","Create a new GitHub repository for your project","How did you structure your repository for professional presentation? What naming conventions did you establish? Which files did you include in your initial commit?","Repository is organized with folders for source code, notebooks, data, checklists, and screenshots. Naming conventions use clear, lowercase names. Initial commit includes a README, .gitignore, and .gitattributes. Additional folders and files for data, notebooks, and source code will be added as the project progresses. Screenshot uploaded: githubrepo.png","âœ…ðŸ“· Done"
"3.15","Sketch dashboard wireframe for Tableau Public","What layout decisions supported your business impact questions? How did you prioritize visual hierarchy? What user experience considerations influenced your design?","The dashboard wireframe prioritizes KPIs at the top (Median Employee Growth, High-Growth Companies, Funding), filters on the left, and main charts (Top 10 by Employee Growth, Growth Distribution, Growth vs. Funding) in the center, with a geographic map at the bottom. Layout is clear, fast to scan, and interactive. Screenshot uploaded: dashboardwireframe.jpg","âœ…ðŸ“· Done"
"3.16","Identify key metrics and KPIs for dashboard","Which metrics directly answered stakeholder questions? How did you validate KPI relevance? What benchmarks did you establish for success measurement?","kpiselection.md","âœ…ðŸ“· Done"
"3.17","Connect Tableau Public to PostgreSQL","What connection challenges did you overcome? Which authentication methods worked best? How did you optimize data refresh performance?","Tableau Public does not support direct PostgreSQL connections; it only allows connections to local files (CSV, Excel) and Google Sheets. I exported the cleaned data from PostgreSQL to a CSV file and connected Tableau Public to this CSV for all dashboard development. No database authentication was required; the connection was established by selecting the CSV file from my local system. Screenshot uploaded: tableauconnection.png","âœ…ðŸ“· Done"
"3.18","Build visualizations (charts, KPIs, filters)","Which chart types most effectively communicated your insights? How did you handle data limitations in visual design? What interactivity features enhanced user understanding?","Created KPI cards for Median Employee Growth, Number of High-Growth Companies, and Total Funding. Used a bar chart for Top 10 Companies by Employee Growth, a histogram for employee growth distribution, a scatter plot for employee growth vs. total funding, and a map for geographic distribution. Data limitations were addressed by focusing on fields with high completeness and using medians to reduce outlier impact. Interactivity features include filters and tooltips in Tableau. Screenshot uploaded: tableaucharts.png","âœ…ðŸ“· Done"
"3.19","Combine visuals into an interactive dashboard","How did you ensure dashboard coherence and professional appearance? What user testing informed your final design? Which performance optimizations did you implement?","The Tableau dashboard combines all key KPIs and visualizations in a single, interactive view. KPIs are placed at the top for quick insights, with supporting charts (bar, histogram, scatter, map) arranged for logical flow and clarity. Filters and tooltips enhance interactivity and user exploration. The layout was refined for readability and fast scanning. Performance was optimized by using a CSV extract and limiting visual complexity. The final design was reviewed for clarity and business relevance. Screenshot uploaded: tableaudashboard.png","âœ…ðŸ“· Done"
"4.20","Document your process in GitHub README","How did you structure your project narrative for maximum employer impact? Which technical details demonstrated your competency? How did you balance technical depth with accessibility?","See README.md","âœ…ðŸ“· Done"
"4.21","Summarize key findings and business impact","What quantifiable business value did your analysis create? How did you translate technical findings into executive-level insights? Which recommendations had the highest ROI potential?","findingssummary.md","âœ…ðŸ“· Done"
"4.22","Publish dashboard to Tableau Public","What privacy considerations influenced your publication decisions? How did you optimize for public accessibility? What metadata enhanced discoverability?","The Tableau dashboard was published to Tableau Public using data from Growjo, which is publicly available and contains only company-level, non-personal information. There are no privacy concerns with this dataset. The dashboard is set to public access, includes descriptive titles, tags, and a clear project summary for discoverability. The Tableau Public link is included in the README and project documentation. Screenshot uploaded: tableaupublicpublish.png","âœ…ðŸ“· Done"
"4.23","Prepare project for portfolio website/LinkedIn/Notion","How did you craft your project story for maximum professional impact? Which achievements highlighted your analytical thinking? How did you demonstrate business acumen alongside technical skills?","See portfolioprep.md. Project summary and links added to Notion. Screenshot uploaded: portfolioprep.png","âœ…ðŸ“· Done"